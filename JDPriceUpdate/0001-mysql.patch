From f2fe24775ff9ae8ced75e6c012b360171fd3554e Mon Sep 17 00:00:00 2001
From: zhaiyujie <zhaiyujie@viewhigh.com>
Date: Thu, 30 Aug 2018 20:41:13 +0800
Subject: [PATCH 1/2] =?UTF-8?q?=E5=AF=BC=E5=87=BA=E5=88=B0mysql?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 JDSpider/pipelines.py        | 153 ++++++++++++++++++++++++++++++++++++++++++-
 JDSpider/settings.py         |   6 ++
 JDSpider/spiders/JDSpider.py |   5 ++
 3 files changed, 162 insertions(+), 2 deletions(-)

diff --git a/JDSpider/pipelines.py b/JDSpider/pipelines.py
index 10db98b..4f342aa 100644
--- a/JDSpider/pipelines.py
+++ b/JDSpider/pipelines.py
@@ -4,12 +4,44 @@
 #
 # Don't forget to add your pipeline to the ITEM_PIPELINES setting
 # See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html
+import csv
 
 import pandas as pd
 from JDSpider.items import *
+from scrapy import log
+import MySQLdb.cursors
+from twisted.enterprise import adbapi
+
+from scrapy.xlib.pydispatch import dispatcher
+from scrapy import signals
+
 
 class JdspiderPipeline(object):
-    def __init__(self):
+    def __init__(self,dbpool):
+        self.dbpool = dbpool
+        # Instantiate DB
+        # self.dbpool = adbapi.ConnectionPool('MySQLdb',
+        #                                     host='locahost',
+        #                                     user='root',
+        #                                     passwd='root',
+        #                                     port='3306',
+        #                                     db='test',
+        #                                     charset='utf8',
+        #                                     use_unicode=True,
+        #                                     cursorclass=MySQLdb.cursors.DictCursor
+        #                                     )
+        # dispatcher.connect(self.close_spider, signals.spider_closed)
+
+        self.categoryCSV = open('category.csv', 'a', newline='')  # 设置newline，否则两行之间会空一行
+        self.categoryWriter = csv.writer(self.categoryCSV)
+        self.csvProductFile = open('product.csv', 'a', newline='')  # 设置newline，否则两行之间会空一行
+        self.productWriter = csv.writer(self.csvProductFile)
+        self.csvShopFile = open('shop.csv', 'a', newline='')  # 设置newline，否则两行之间会空一行
+        self.shopWriter = csv.writer(self.csvShopFile)
+        self.csvCommentFile = open('CommentItem.csv', 'a', newline='')  # 设置newline，否则两行之间会空一行
+        self.commentWriter = csv.writer(self.csvCommentFile)
+
+
         self.Categories = pd.DataFrame()
         self.Products = pd.DataFrame()
         self.Shop = pd.DataFrame()
@@ -18,6 +50,21 @@ class JdspiderPipeline(object):
         self.CommentSummary = pd.DataFrame()
         self.HotCommentTag = pd.DataFrame()
 
+    @classmethod
+    def from_settings(cls, settings):
+        dbparms = dict(
+            host=settings["MYSQL_HOST"],
+            db=settings["MYSQL_DBNAME"],
+            user=settings["MYSQL_USER"],
+            passwd=settings["MYSQL_PASSWORD"],
+            charset='utf8',
+            cursorclass=MySQLdb.cursors.DictCursor,
+            use_unicode=True,
+        )
+        dbpool = adbapi.ConnectionPool("MySQLdb", **dbparms)
+
+        return cls(dbpool)
+
     def close_spider(self, spider):
         self.Categories.to_csv("categories.csv", sep='\t')
         self.Products.to_csv("products.csv", sep='\t')
@@ -26,26 +73,64 @@ class JdspiderPipeline(object):
         self.CommentImage.to_csv("commentImage.csv", sep='\t')
         self.CommentSummary.to_csv("commentSummary.csv", sep='\t')
         self.HotCommentTag.to_csv("hotCommentTag.csv", sep='\t')
+        self.categoryCSV.close()
+        self.csvProductFile.close()
+        self.csvShopFile.close()
+        self.csvCommentFile.close()
+
 
     def process_item(self, item, spider):
         """ 判断item的类型，并作相应的处理，再入数据库 """
+
         if isinstance(item, CategoriesItem):
             try:
+                # dataCategory = dict(item)
+                query = self.dbpool.runInteraction(self._insert_category_record, item)
+                query.addErrback(self.handle_error, item, spider)
+
+                # self.categoryWriter.writerow(dataCategory.values())
                 self.Categories.append(pd.DataFrame(dict(item).items(), columns=dict(item).keys()))
             except Exception:
                 pass
         elif isinstance(item, ProductsItem):
             try:
+                # dataProduct=dict(item)
+                favourite_description = item['favourableDesc1']
+                query = self.dbpool.runInteraction(self._insert_product_record, item)
+
+                query.addErrback(self.handle_error, item, spider)
+                # csvProductFile = open('product.csv', 'a', newline='')  # 设置newline，否则两行之间会空一行
+                # productWriter = csv.writer(csvProductFile)
+                # self.productWriter.writerow(dataProduct.values())
+                # self.csvProductFile.close()
+
                 self.Products.append(pd.DataFrame(dict(item).items(), columns=dict(item).keys()))
             except Exception:
                 pass
         elif isinstance(item, ShopItem):
             try:
+                # dataShop = dict(item)
+                query = self.dbpool.runInteraction(self._insert_shop_record, item)
+                #
+                query.addErrback(self.handle_error, item, spider)
+                # csvShopFile = open('shop.csv', 'a', newline='')  # 设置newline，否则两行之间会空一行
+                # shopWriter = csv.writer(csvShopFile)
+                # self.shopWriter.writerow(dataShop.values())
+
+                # csvShopFile.close()
                 self.Shop.append(pd.DataFrame(dict(item).items(), columns=dict(item).keys()))
             except Exception:
                 pass
         elif isinstance(item, CommentItem):
             try:
+                query = self.dbpool.runInteraction(self._insert_comment_record, item)
+
+                query.addErrback(self.handle_error, item, spider)
+                # dataComment = dict(item)
+                # csvCommentFile = open('CommentItem.csv', 'a', newline='')  # 设置newline，否则两行之间会空一行
+                # commentWriter = csv.writer(csvCommentFile)
+                # self.commentWriter.writerow(dataComment.values())
+                # csvCommentFile.close()
                 self.Comment.append(pd.DataFrame(dict(item).items(), columns=dict(item).keys()))
             except Exception:
                 pass
@@ -64,4 +149,68 @@ class JdspiderPipeline(object):
                 self.HotCommentTag.append(pd.DataFrame(dict(item).items(), columns=dict(item).keys()))
             except Exception:
                 pass
-        return item
\ No newline at end of file
+        return item
+    def _insert_category_record(self, cursor, item):
+        category_id = item['_id']
+        name = item['name']
+        url = item['url']
+        sql = "INSERT INTO product_category VALUES (null,'%s', '%s', '%s')" % \
+              (category_id, name, url)
+        cursor.execute(sql)
+        print ("_insert_category_record")
+
+    def _insert_product_record(self, cursor, item):
+        name = item['name']
+        url = item['url']
+        product_id= item['_id']
+        shop_id= item['shopId']
+        description= item['description']
+        favourite_description= item['favourableDesc1']
+        category_id=item['category']
+        original_price = item['originalPrice']
+        really_price = item['reallyPrice']
+        # divivor_comment_count=item['commentCount']
+        sql = "INSERT INTO product_item VALUES (null,'%s', '%s', '%s','%s', '%s', '%s','%s','%s','%s','%s')" % \
+              (name, url, product_id,shop_id,description,favourite_description,category_id,0,original_price,really_price)
+        cursor.execute(sql)
+        print("_insert_product_record ")
+
+    def _insert_shop_record(self, cursor, item):
+        name = item['name']
+        url = item['url1']
+        shop_id = item['shopId']
+        vender_id =item['venderId']
+        sql = "INSERT INTO shop_item VALUES (null,'%s', '%s', '%s','%s')" % \
+              (name, url, shop_id, vender_id)
+        cursor.execute(sql)
+        print("_insert_product_record ")
+
+
+    def _insert_comment_record(self, cursor, item):
+        commentid = item['_id']
+        product_id = item['productId']
+        content = item['content']
+        create_time = item['creationTime']
+        reference_name = item['referenceName']
+        reference_type = item['referenceType']
+        first_category = item['firstCategory']
+        second_category = item['secondCategory']
+        third_category = item['thirdCategory']
+        user_client_show = item['userClientShow']
+        is_mobile = item['isMobile']
+        score = item['score']
+
+
+        sql = "INSERT INTO comment_item VALUES (null,'%s', '%s', '%s','%s', '%s', '%s','%s','%s','%s','%s','%s','%s')" % \
+              (commentid, product_id, content,create_time,reference_name,reference_type,first_category,second_category,third_category,user_client_show
+               ,is_mobile,score)
+        cursor.execute(sql)
+        print("_insert_comment_record ")
+
+
+    def handle_error(self, failure, item, spider):
+        # 处理异步插入的异常
+        print(failure)
+
+
+
diff --git a/JDSpider/settings.py b/JDSpider/settings.py
index 606bf47..39846c1 100644
--- a/JDSpider/settings.py
+++ b/JDSpider/settings.py
@@ -88,3 +88,9 @@ ITEM_PIPELINES = {
 #HTTPCACHE_DIR = 'httpcache'
 #HTTPCACHE_IGNORE_HTTP_CODES = []
 #HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'
+
+MYSQL_HOST = "localhost"
+MYSQL_DBNAME = "test"
+MYSQL_USER = "root"
+MYSQL_PASSWORD = "root"
+MYSQL_PORT = "3306"
\ No newline at end of file
diff --git a/JDSpider/spiders/JDSpider.py b/JDSpider/spiders/JDSpider.py
index 09ad552..2a55c80 100644
--- a/JDSpider/spiders/JDSpider.py
+++ b/JDSpider/spiders/JDSpider.py
@@ -10,6 +10,7 @@ import re
 import logging
 import json
 import requests
+import MySQLdb
 from scrapy import Spider
 from scrapy.selector import Selector
 from scrapy.http import Request
@@ -138,7 +139,11 @@ class JDSpider(Spider):
         # price
         response = requests.get(url=price_url + product_id)
         price_json = response.json()
+        # if(price_json[0].has_key('p')):
         productsItem['reallyPrice'] = price_json[0]['p']
+        # else
+        #     productsItem['reallyPrice'] = 0
+
         productsItem['originalPrice'] = price_json[0]['m']
 
         # 优惠
-- 
2.9.0.windows.1

